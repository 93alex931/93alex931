{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "#грузим библиотеки\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import notebook\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 350 # чтобы лучше текст прочитать\n",
    "CV = 3\n",
    "RANDOM_STATE = 12345\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = 'C:Downloads//toxic_comments.csv'\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                            text  \\\n",
       "0                                                                                      Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                               D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                      Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences...   \n",
       "4                                                                                                                                                                                                                                                                                            You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим количество коментариев токсичных и нет. Так же взглянем на разметку , которую нам предоставили.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "\"\n",
      "More\n",
      "I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n",
      "\n",
      "There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
      "You, sir, are my hero. Any chance you remember what page that's on?\n"
     ]
    }
   ],
   "source": [
    "for i in df[df.toxic == 0]['text'].head(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n"
     ]
    }
   ],
   "source": [
    "for i in df[df.toxic == 1]['text'].head(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentense_example = df.iloc[1]['text']\n",
    "# разбиваем на токены\n",
    "tokens = word_tokenize(sentense_example, language='english')\n",
    "# удаляем пунктуацию т.к. не модель будет хуже работать\n",
    "tokens_without_punktuation = [i for i in tokens if i not in string.punctuation]\n",
    "english_stop_words = stopwords.words('english')\n",
    "# в этом пункте она уже без стоп слов и пунктуации\n",
    "tokens_without_stop_words_and_punctuation = [i for i in tokens_without_punktuation if i not in english_stop_words]\n",
    "# приводим к нижнему регистру и удаляем окончания\n",
    "snowball = SnowballStemmer(language='english')\n",
    "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stop_words_and_punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "--------------------\n",
      "Токены: [\"D'aww\", '!', 'He', 'matches', 'this', 'background', 'colour', 'I', \"'m\", 'seemingly', 'stuck', 'with', '.', 'Thanks', '.', '(', 'talk', ')', '21:51', ',', 'January', '11', ',', '2016', '(', 'UTC', ')']\n",
      "--------------------\n",
      "Токены без пунктуации: [\"D'aww\", 'He', 'matches', 'this', 'background', 'colour', 'I', \"'m\", 'seemingly', 'stuck', 'with', 'Thanks', 'talk', '21:51', 'January', '11', '2016', 'UTC']\n",
      "--------------------\n",
      "Токены без пунктуации и стоп слов: [\"D'aww\", 'He', 'matches', 'background', 'colour', 'I', \"'m\", 'seemingly', 'stuck', 'Thanks', 'talk', '21:51', 'January', '11', '2016', 'UTC']\n",
      "--------------------\n",
      "Токены после стеминга: [\"d'aww\", 'he', 'match', 'background', 'colour', 'i', \"'m\", 'seem', 'stuck', 'thank', 'talk', '21:51', 'januari', '11', '2016', 'utc']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Исходный текст: {sentense_example}')\n",
    "print('--------------------')\n",
    "print(f'Токены: {tokens}')\n",
    "print('--------------------')\n",
    "print(f'Токены без пунктуации: {tokens_without_punktuation}')\n",
    "print('--------------------')\n",
    "print(f'Токены без пунктуации и стоп слов: {tokens_without_stop_words_and_punctuation}')\n",
    "print('--------------------')\n",
    "print(f'Токены после стеминга: {stemmed_tokens}')\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language='english')\n",
    "english_stop_words = stopwords.words('english')\n",
    "# функция для общего массива\n",
    "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
    "    tokens = word_tokenize(sentence, language='english')\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    if remove_stop_words:\n",
    "        tokens = [i for i in tokens if i not in english_stop_words]\n",
    "    tokens = [snowball.stem(i) for i in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"d'aww\",\n",
       " 'he',\n",
       " 'match',\n",
       " 'background',\n",
       " 'colour',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'seem',\n",
       " 'stuck',\n",
       " 'thank',\n",
       " 'talk',\n",
       " '21:51',\n",
       " 'januari',\n",
       " '11',\n",
       " '2016',\n",
       " 'utc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_sentence(sentense_example) # проверим работу функции на 1 примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127656, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE)\n",
    "display(test_df.shape)\n",
    "display(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    114593\n",
       "1     13063\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    28753\n",
       "1     3162\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.toxic.value_counts())\n",
    "display(test_df.toxic.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(tokenizer= lambda x: tokenize_sentence(x, remove_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vec.fit_transform(train_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345).fit(features, train_df.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим коммент,модель нам показала негатив проверим его и убедимся,что она верно предсказала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text.iloc[0] # Умри \\n\\nЯ НЕНАВИЖУ ТЕБЯ, ЧУДО, ТЫ НЕ ЗАСЛУЖИВАЕШЬ ЗДЕСЬ МЕСТА'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer= lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    ('model', LogisticRegression(random_state=12345))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.fit(train_df.text, train_df.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения проверим модель сами напишем рандомный коментарий и негативный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.predict(['Hi, is it okay bro. I gonna talk with Alfk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.predict(['Lets go to fucking outside'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "знаем, что нам нужна f1 мера, но без подкрутки точности и полноты мы не добьёмся нужного результат.\n",
    "Следовательно будем смотреть наши результаты Precision and Recall тоже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'предсказания точности на тестовой выборке равен: {precision_score(y_true=test_df.toxic,y_pred=model_pipeline.predict(test_df.text))}')\n",
    "print(f'предсказания полноты на тестовой выборке равен: {recall_score(y_true=test_df.toxic,y_pred=model_pipeline.predict(test_df.text))}')\n",
    "print(f'предсказания f1 меры на тестовой выборке равен: {f1_score(y_true=test_df.toxic,y_pred=model_pipeline.predict(test_df.text))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thresholds = precision_recall_curve(y_true=test_df.toxic, probas_pred=model_pipeline.predict_proba(test_df.text)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(estimator=model_pipeline, X=test_df.text, y=test_df.toxic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "можно попробовать подкурить параметры , если не выйдет то будем передвигаться к подбору гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(prec>0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[27777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_true=test_df.toxic, y_pred=model_pipeline.predict_proba(test_df.text)[:,1] > thresholds[27111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true=test_df.toxic, y_pred=model_pipeline.predict_proba(test_df.text)[:,1] > thresholds[25397])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подберем гиперпараметры для нашей логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipeline = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer= lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    ('model', GridSearchCV(\n",
    "    LogisticRegression(random_state=12345),\n",
    "    param_grid={'C': [0.1, 1, 10.]},\n",
    "    cv=3,\n",
    "    verbose=4\n",
    "    )\n",
    "     )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipeline.fit(train_df.text, train_df.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_up = Pipeline([\n",
    "    ('vec', TfidfVectorizer(tokenizer= lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    ('model', LogisticRegression(random_state=12345,C=10.))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_up.fit(train_df.text, train_df.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_up, rec_up, thresholds_up = precision_recall_curve(y_true=test_df.toxic, probas_pred=model_pipeline_up.predict_proba(test_df.text)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(estimator=model_pipeline_up, X=test_df.text, y=test_df.toxic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый результаты Логистической регрессии на тестовой выборке\n",
      "                                                                 \n",
      "предсказания точности на тестовой выборке равен: 0.8802678219771564\n",
      "предсказания полноты на тестовой выборке равен: 0.6982193064667291\n",
      "предсказания f1 меры на тестовой выборке равен: 0.7787456445993031\n"
     ]
    }
   ],
   "source": [
    "print('Итоговый результаты Логистической регрессии на тестовой выборке')\n",
    "print('                                                                 ')\n",
    "print(f'предсказания точности на тестовой выборке равен: {precision_score(y_true=test_df.toxic,y_pred=model_pipeline_up.predict(test_df.text))}')\n",
    "print(f'предсказания полноты на тестовой выборке равен: {recall_score(y_true=test_df.toxic,y_pred=model_pipeline_up.predict(test_df.text))}')\n",
    "print(f'предсказания f1 меры на тестовой выборке равен: {f1_score(y_true=test_df.toxic,y_pred=model_pipeline_up.predict(test_df.text))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Посмотрели на наши данные определи, что качество разметки данных отличное для выполнения поставленной задачи.\n",
    "\n",
    "2. Подготовили нашу модель для обучения.\n",
    "\n",
    "3. Провели Лемматизация данных.\n",
    "\n",
    "4. Проверили точность и полноту модели на тестовой выборке.\n",
    "\n",
    "5. Нашли наилучшие параметры на `LogisticRegression`.\n",
    "\n",
    "*Мы добились результата на логистической регрессии `f1 меры 0.77` и выполнили задание заказчика !*"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2571,
    "start_time": "2022-07-12T19:06:48.753Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-12T19:07:31.455Z"
   },
   {
    "duration": 3326,
    "start_time": "2022-07-12T19:18:29.658Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-12T19:18:42.320Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-12T19:18:50.900Z"
   },
   {
    "duration": 841,
    "start_time": "2022-07-12T19:25:00.152Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-12T19:25:01.582Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-12T19:25:02.009Z"
   },
   {
    "duration": 2669,
    "start_time": "2022-07-13T12:23:44.809Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-13T12:24:06.497Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-13T12:24:23.112Z"
   },
   {
    "duration": 2727,
    "start_time": "2022-07-13T12:24:34.361Z"
   },
   {
    "duration": 194,
    "start_time": "2022-07-13T12:24:43.402Z"
   },
   {
    "duration": 822,
    "start_time": "2022-07-13T12:24:47.080Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-13T12:24:58.702Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-13T12:25:06.199Z"
   },
   {
    "duration": 237,
    "start_time": "2022-07-13T12:25:40.158Z"
   },
   {
    "duration": 18,
    "start_time": "2022-07-13T12:25:52.755Z"
   },
   {
    "duration": 9,
    "start_time": "2022-07-13T12:26:04.614Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-13T12:26:33.749Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-13T12:26:43.719Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-13T12:26:58.562Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-13T12:27:37.000Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-13T12:28:32.493Z"
   },
   {
    "duration": 38,
    "start_time": "2022-07-13T12:28:38.106Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-13T12:28:58.204Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-13T12:29:15.303Z"
   },
   {
    "duration": 140310,
    "start_time": "2022-07-13T12:29:36.592Z"
   },
   {
    "duration": 55026,
    "start_time": "2022-07-13T12:31:56.905Z"
   },
   {
    "duration": 92,
    "start_time": "2022-07-13T12:32:51.933Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-13T12:32:52.028Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-13T12:32:52.038Z"
   },
   {
    "duration": 205410,
    "start_time": "2022-07-13T12:32:52.047Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-13T12:36:17.459Z"
   },
   {
    "duration": 54,
    "start_time": "2022-07-13T12:36:17.471Z"
   },
   {
    "duration": 118825,
    "start_time": "2022-07-13T12:36:17.528Z"
   },
   {
    "duration": 39182,
    "start_time": "2022-07-13T12:38:16.355Z"
   },
   {
    "duration": 39695,
    "start_time": "2022-07-13T12:38:55.539Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-13T12:39:35.236Z"
   },
   {
    "duration": 569082,
    "start_time": "2022-07-13T12:39:35.243Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-13T12:49:04.327Z"
   },
   {
    "duration": 202390,
    "start_time": "2022-07-13T12:49:04.336Z"
   },
   {
    "duration": 35759,
    "start_time": "2022-07-13T12:52:26.728Z"
   },
   {
    "duration": 37421,
    "start_time": "2022-07-13T12:53:02.489Z"
   },
   {
    "duration": 104891,
    "start_time": "2022-07-13T12:53:39.913Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-13T13:03:47.902Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-13T13:04:04.114Z"
   },
   {
    "duration": 37763,
    "start_time": "2022-07-13T13:04:25.230Z"
   },
   {
    "duration": 36925,
    "start_time": "2022-07-13T13:05:02.995Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-13T13:07:02.578Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-13T13:07:08.979Z"
   },
   {
    "duration": 36295,
    "start_time": "2022-07-13T13:07:13.672Z"
   },
   {
    "duration": 36378,
    "start_time": "2022-07-13T13:07:49.969Z"
   },
   {
    "duration": 2458,
    "start_time": "2022-07-23T16:34:06.296Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-23T16:34:08.756Z"
   },
   {
    "duration": 2777,
    "start_time": "2022-07-23T16:34:08.763Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-23T16:34:11.542Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-23T16:34:11.550Z"
   },
   {
    "duration": 249,
    "start_time": "2022-07-23T16:34:11.564Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-23T16:34:11.814Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-23T16:34:11.831Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-23T16:34:14.593Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-23T16:34:14.971Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-23T16:34:16.180Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-23T16:34:16.991Z"
   },
   {
    "duration": 33,
    "start_time": "2022-07-23T16:34:17.373Z"
   },
   {
    "duration": 9,
    "start_time": "2022-07-23T16:34:17.851Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-23T16:34:18.242Z"
   },
   {
    "duration": 138305,
    "start_time": "2022-07-23T16:34:19.056Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
