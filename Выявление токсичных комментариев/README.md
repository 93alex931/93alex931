# Выявление токсичных комментариев

**Статус:** Завершён.

**Цель проекта:** Обучить модель классификации, которая выявит среди текстов токсичные и отправит их на модерацию.

**Результаты работы:**
   - Мы выполнили очистку данных и разделили их на обучающую и тестовую выборки.
   - Применили три подхода к векторизации текстов в датасете:
       - Bag of words,
       - TF-IDF,
       - PipeLine.
- Испытали лемматизацию `WordNet` и стемминг `SnowballStemmer` из пакета `NLTK`. Второй вариант оказался отличным.
- Выяснили опытным путём, что восклицательные знаки в текстах **не свидетельствуют** об их токсичности.
- При помощи PipeLine мы добились результата на логистической регрессии f1 меры 0.77 и выполнили задание заказчика !
---
